import os
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
#os.environ["CUDA_VISIBLE_DEVICES"]='1' 
import glob
import pandas as pd
import numpy as np
import joblib
from imutils import paths
from sklearn.preprocessing import LabelBinarizer
from tqdm import tqdm
from ipywidgets import IntProgress
import gc
import torchvision
from torchvision import datasets, models, transforms
import torch
import random
import albumentations
#from albumentations.pytorch import ToTensorV2
import matplotlib.pyplot as plt
import argparse
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import time
from PIL import Image
from torchvision import models as models
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader, ConcatDataset, default_collate
from torch.autograd import Variable
from matplotlib import pyplot
from sklearn.metrics import mean_squared_error
import math
import itertools   
from self_attention_cv import ViT
from sklearn.model_selection import KFold
print(os.cpu_count())
batch_size=64
k_folds = 5
results = {}
torch.manual_seed(42)
from visdom import Visdom



def reset_weights(m):
  '''
    Try resetting model weights to avoid
    weight leakage.
  '''
  for layer in m.children():
        if hasattr(layer, 'reset_parameters'):
            print(f'Reset trainable parameters of layer = {layer}')
            layer.reset_parameters()


class tcnn(nn.Module):
    def __init__(self):
        super(tcnn,self).__init__()
        self.conv3d1=nn.Conv3d(256,64,kernel_size=(3,3,3))
        self.conv3d1_bn=nn.BatchNorm3d(64)
        self.conv3d_relu=nn.ReLU()
        #self.conv3d_pool=nn.MaxPool3d(kernel_size=(1, 1, 1))
        self.conv3d2=nn.Conv3d(64,512,kernel_size=(7,1,1))
        self.conv3d2_bn2=nn.BatchNorm3d(512)
        self.conv3d_relu2=nn.ReLU()
        self.conv3d_pool2=nn.MaxPool3d(kernel_size=(3, 1, 1))
    def forward(self, x):
        out = self.conv3d1(x)
        out = self.conv3d1_bn(out)
        out = self.conv3d_relu(out)
        #out = self.conv3d_pool(out)
        out = self.conv3d2(out)
        out = self.conv3d2_bn2(out)
        out = self.conv3d_relu2(out)
        out = self.conv3d_pool2(out)
        out = out.view(out.size(0), -1)
        return out  


def load_tcnn(weights_path=None, **kwargs):
    model = tcnn().to(device)
    if weights_path:
        state_dict = torch.load(weights_path).to(device)
        model.load_state_dict(state_dict).to(device)
    return model

 
def Regression():
    reg = nn.Sequential(
        nn.BatchNorm1d(3072),
        nn.Dropout(0.5),
        nn.Linear(3072,1))
        
    return reg

    
class PreTrained_res(nn.Module):
    def __init__(self):
        super(PreTrained_res,self).__init__()
        pretrained=load_tcnn().to(device)
        self.feature_extraction=pretrained
        self.Regression=Regression()
        
    def forward(self,x):
        x=self.feature_extraction(x)
        depr=self.Regression(x)
        return depr


#validation function
def validate(model, test_dataloader):
    print('Validating')
    #model.eval()
    val_running_loss = 0.0
    val_running_loss2 = 0.0
    num_iterations=0;
    with torch.no_grad():
        for i, data in tqdm(enumerate(test_dataloader,0),total=int(len(test_dataloader))):
            num_iterations+=1;
            
            inputs, target = data[0].to(device), data[1].to(device)
            inputs=torch.reshape(inputs,(64,256,27,3,3)).to(device)
            outputs = model(inputs)
            target=torch.reshape(target,(64,1)).to(device)
            #target=target.resize(108,1)
            cri=nn.MSELoss()
            loss=torch.sqrt(cri(outputs, target))
            loss2=MAE(outputs,target)
            val_running_loss += loss.item()
            val_running_loss2 += loss2.item()
        val_rmse = val_running_loss/num_iterations
        val_mae = val_running_loss2/num_iterations
        #val_accuracy = 100. * val_running_correct/len(test_dataloader.dataset)
        #print("len test loader dataset:", len(test_dataloader.dataset), "num_iterations*BS", num_iterations*108)
        print(f'Val RMSE: {val_rmse:.4f}, Val MAE: {val_mae:.2f}')       
        return val_rmse, val_mae

# training function
def fit(model, train_dataloader):
    print('Training')
    #model.train()
    train_running_loss = 0.0
    train_running_loss2 = 0.0 
    num_iterations=0
    
    for i, data in tqdm(enumerate(train_dataloader,0),total=int(len(train_dataloader))):
        
        num_iterations+=1 
        inputs, target = data[0].to(device), data[1].to(device)
        #print(inputs)
        inputs=torch.reshape(inputs,(64,256,27,3,3)).to(device)
        #print("inputs.size",inputs.size(0))
        optimizer.zero_grad()
        outputs = model(inputs).to(device)
        target=torch.reshape(target,(64,1)).to(device)
        #target=target.resize(108,1)
        cri=nn.MSELoss()
        loss=torch.sqrt(cri(outputs, target)).to(device)
        loss2 = MAE(outputs, target).to(device)
        loss.backward()
        #loss2.backward()
        optimizer.step()
        train_running_loss += loss.item()
        train_running_loss2 += loss2.item()
         
    train_rmse = train_running_loss/num_iterations
    train_mae = train_running_loss2/num_iterations 
    #print("len train loader dataset:", len(train_dataloader.dataset), "num_iterations*BS", num_iterations*108)
    print(f"Train RMSE: {train_rmse:.4f}, Train MAE: {train_mae:.2f}")      
    return train_rmse, train_mae

class NaturalImageDataset(Dataset):
    def __init__(self, path, labels):
        self.X = path
        self.y = labels
        self.transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize([144, 144]),
                #albumentations.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),
                #albumentations.augmentations.transforms.GaussNoise (var_limit=(10.0, 50.0), mean=0, per_channel=True, always_apply=True, p=1),
                #albumentations.augmentations.transforms.FancyPCA (alpha=0.1, always_apply=True, p=1),
                #albumentations.RandomCrop(height=224, width=224),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])
                
            
                #ToTensorV2() 
            ])
    def __len__(self):
        return (len(self.X))
    
    def __getitem__(self, i):
        path=(self.X[i])
        image = Image.open(self.X[i])
        convert_tensor=transforms.ToTensor()
        image=convert_tensor(image)
        image = self.transform(image)
        image=image
        ##model2=ViT(img_dim=256,in_channels=3,patch_dim=16,dim=512)
        ####image=torch.rand(80,3,256,256)
        ##image=model2(image)
        #print(image.shape)
        label = self.y[i]
        
        return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.float)

print(torch.cuda.is_available())
device = ('cuda:1' if torch.cuda.is_available() else 'cpu')
#device='cpu'
print(f"Computation device: {device}")

# read the data.csv file and get the image paths and labels
files = os.path.join("/data/ghazal/AVEC2014FACE/new/train/train1/", "*.csv")
files=glob.glob(files)
df=pd.concat(map(pd.read_csv,files),ignore_index=True)

X = df.image_path2.values
y = df.target.values


files = os.path.join("/data/ghazal/AVEC2014FACE/new/val/val1/", "*.csv")
files=glob.glob(files)
df2=pd.concat(map(pd.read_csv,files),ignore_index=True)
X2 = df2.image_path2.values
y2 = df2.target.values

(xtrain, xtest, ytrain, ytest) = (X, X2, y, y2)

train_data = NaturalImageDataset(xtrain, ytrain)
test_data = NaturalImageDataset(xtest, ytest)
#dataset = ConcatDataset([train_data, test_data])

# Define the K-fold Cross Validator
##kfold = KFold(n_splits=k_folds, shuffle=True)

##for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):
    ##print(f'FOLD {fold}')
    ##print('--------------------------------')
    # Sample elements randomly from a given list of ids, no replacement.
    
    #train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)
    
    #test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)
    #kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}
    #trainloader = DataLoader(dataset, batch_size=108,shuffle=False,drop_last=True, num_workers=8,pin_memory=True, sampler=train_ids)
trainloader = DataLoader(train_data, batch_size=64,shuffle=False,drop_last=True, num_workers=1,pin_memory=False)
testloader = DataLoader(test_data, batch_size=64,shuffle=False,drop_last=True, num_workers=1,pin_memory=False)
    #testloader = DataLoader(dataset, batch_size=108,shuffle=False,drop_last=True, num_workers=8,pin_memory=True, sampler=test_ids)
print("len",len(train_data),len(test_data))
model_ft = PreTrained_res().to(device)
model_ft = model_ft.to(device)
model_ft.apply(reset_weights)
MAE = torch.nn.L1Loss()
    #loss_function=torch.nn.MSELoss()
optimizer = optim.Adam(model_ft.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)
train_rmse , train_mae = [], []
val_rmse , val_mae = [], []
start = time.time()



for epoch in range(10):
    print("Epoch:", epoch+1)
        
    train_epoch_loss, train_epoch_MAE = fit(model_ft, trainloader)
    train_rmse.append(train_epoch_loss)
    train_mae.append(train_epoch_MAE)
    val_epoch_loss, val_epoch_MAE = validate(model_ft, testloader)
    val_rmse.append(val_epoch_loss)
    val_mae.append(val_epoch_MAE)
    end = time.time()
    print(f"{(end-start)/60:.3f} minutes")
    # accuracy plots
plt.figure(figsize=(10, 7))
plt.plot(train_mae, color='green', label='train MAE')
plt.plot(val_mae, color='blue', label='validataion MAE')
plt.xlabel('Epochs')
plt.ylabel('MAE')
plt.legend()
    #plt.savefig('/data/ghazal/Balanceddata/graphs/norm/accuracy4.png')
plt.show()
    # loss plots
plt.figure(figsize=(10, 7))
plt.plot(train_rmse, color='orange', label='train RMSE')
plt.plot(val_rmse, color='red', label='validataion RMSE')
plt.xlabel('Epochs')
plt.ylabel('RMSE')
plt.legend()
    #plt.savefig('/data/ghazal/Balanceddata/graphs/norm/loss4.png')
plt.show()
#save the model to disk
print('Saving model...')
torch.save(model_ft.state_dict(), '/home/ghazal/data/Code/Experiments/Depression/14/test3dcnn/model1.pth')
